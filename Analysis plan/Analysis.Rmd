---
title: 'Examining the role of orthographic neighbourhood effects during lateralised lexical decision paradigms: A meta-analysis'
author: "Adam Parker"
date: "03/06/2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

This markdown file covers the proposed analysis for a meta-analysis of orthographic Nsize effects in the right and left visual field. As we are primarily interested in the effect size in each hemifield, rather than the reliability of interaction between visual field and Nsize, we choose to conduct two meta-analyses testing the main effect in each.

This Rmardown accompanies a pre-registration on the OSF: https://osf.io/vknbp/files/

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reshape2)
library(gridExtra) 
library(grid)
library(formatR)
library(meta)
library(metafor)
library(tidyverse)
library(yarrr)
library(forestplot)
require(gridExtra)
require(dmetar)
options(scipen=999)

# make it reproducible
set.seed(123)
```

# PRISMA figure

Before we get into the analys, let's summarise inclusion/exclusion at each step. 

```{r PRISMA}
library(metagear)
# PUBLISHED LITERATURE
phases <- c("START_PHASE: 610 studies identified through database searching and key paper references",
            "232 studies after duplicates removed",
            "232 of studies with title and abstract screened",
            "EXCLUDE_PHASE: 225 studies excluded",
            "8 full-text articles assessed for eligibility",
            "EXCLUDE_PHASE: 1 full-text articles excluded, published thesis chapters",
            "7 studies included for further review and data extraction")
thePlot <- plot_PRISMA(phases, colWidth = 28, excludeDistance = 1)

# FORWARD SEARCHES
phases2 <- c("START_PHASE: 237 studies identified through forward searches of the cited literature",
            "41 studies after duplicates removed",
            "41 of studies with title and abstract screened",
            "EXCLUDE_PHASE: 41 studies excluded",
            "0 studies included for further review and data extraction")
thePlot2 <- plot_PRISMA(phases2, excludeDistance = 1)
```

# Random effects models

We chose to use a random effects model as the studies will differ with several respects: language of participants, Nsizes, etc. This is done seperately for the LVF and RVF.

The below output includes the estimate from the random-effects models, measures of heterogeneity, and precision which are all covered in the registration document. The anlayses are run using the rma() function from the **metafor** package. The effect sizes and variance are calculated using a function (ES) that uses the equations presented in Borenstein et al. (2009) for calculating variances for within subjects designs. 

We also conduct sensitivty analysis where the estimated correlation is replaced.

## Right visual field

First, read the data.

```{r simulateR}
data <- read.csv("extracted_dat.csv", na.strings = " ")
# remove first blank row
data <- data[-1,]
# now get the correlations for the RVF
corrR <- mean(data$r.1, na.rm= TRUE)
# create RVF data 
RVF_dat <- dplyr::select(data, Source.name, Full.title, Source.year, RVF.High.N, RVF.High.N.sd, RVF.Low.N, RVF.Low.N.sd, Sample.size)
# rename for package
RVF_dat <- RVF_dat %>% 
  rename(
    study    = Full.title,
    highN    = RVF.High.N,
    highN_sd = RVF.High.N.sd,
    lowN     = RVF.Low.N,
    lowN_sd  = RVF.Low.N.sd)
# add columns
RVF_dat$corr <- corrR
RVF_dat$VF <- "RVF"
# ensure formatted correctly
RVF_dat$sample_size <- as.numeric(RVF_dat$Sample.size)
RVF_dat$highN <- as.numeric(as.character(RVF_dat$highN))
RVF_dat$highN_sd <- as.numeric(as.character(RVF_dat$highN_sd))
RVF_dat$lowN <- as.numeric(as.character(RVF_dat$lowN))
RVF_dat$lowN_sd <- as.numeric(as.character(RVF_dat$lowN_sd))
RVF_dat$corr <- as.numeric(as.character(RVF_dat$corr))
RVF_dat$study <- as.character(RVF_dat$study)
```

Now that we have the data in the correct format, we need to calculate the mean difference for a within subjects design. We do this using a function based on the formula presented in Borenstein, Hedges, Higgins, and Rothsetin (2009).

```{r withinES}
ES<- function(df, M1, M2, S1, S2, N, r){
    # mean difference
    df$MD<- M1-M2 # equation 4.12
    # standard deviation of the difference
    df$sdif<- sqrt(S1^2 + S2^2 - 2*r*S1*S2) # equation 4.15
    # varaince 
    df$var<- (df$sdif^2)/N # equation 4.13
    # standard error
    df$se<- sqrt(df$var) # equation 4.14
    return(df)
}
```

Now we can start the proposed analysis. 

```{r analysesR}
# calculate the ES
#W do this for RVF
RVF.ES <- ES(RVF_dat, RVF_dat$highN, RVF_dat$lowN, RVF_dat$highN_sd, RVF_dat$lowN_sd, RVF_dat$sample_size, RVF_dat$corr)
# now run the meta analysis
RVF.model <- rma(yi= MD, vi= var, sei= se, data=RVF.ES, method="SJ", test="knha" , digits=3, slab = study)
# print
RVF.model
regtest(RVF.model)
# plot
forest(RVF.model)
grid.text("(B)", .5, .85)
# FUNNEL plots
# set up 2x2 array for plotting
par(mfrow=c(2,2))
# draw funnel plots
funnel(RVF.model, main="Standard Error [RVF]", xlab="Effect size (ms)")
funnel(RVF.model, yaxis="vi", main="Sampling Variance [RVF]", xlab="Effect size (ms)")
funnel(RVF.model, yaxis="seinv", main="Inverse Standard Error [RVF]", xlab="Effect size (ms)")
funnel(RVF.model, yaxis="vinv", main="Inverse Sampling Variance [RVF]", xlab="Effect size (ms)")
```

The estimate is significantly different from zero, so we can conlcude that the effect is truely inhibitory in the RVF/left hemisphere. Now let's run some sensitivity analyses using predetermined levels of correlation.

```{r sensitivityR}
# specify correlations
corlist <- c(.2, .5, .8)
# create temporary data to write to before placing within forCurve
senseDat <- data.frame(matrix(ncol = 5, nrow = length(corlist)))
  colnames(senseDat) <- c("cor", "beta", "CI-", "CI+", "p")
# set row counter
myrow <- 0
# start sensiticity analysis
for (i in corlist) {
  
  RVF.ES <- ES(RVF_dat, RVF_dat$highN, RVF_dat$lowN, RVF_dat$highN_sd, RVF_dat$lowN_sd, RVF_dat$sample_size, i)
  # now run the meta analysis
  RVF.model <- rma(yi= MD, vi= var, sei= se, data=RVF.ES, method="SJ", test="knha" , digits=3)

  # flip counter
  myrow <- myrow+1
  # take the useful estimates
  senseDat$cor[myrow]   <- as.numeric(i) # cor
  senseDat$beta[myrow]  <- as.numeric(RVF.model[2]) # beta
  senseDat$p[myrow]     <- as.numeric(RVF.model[5]) # p
  senseDat$`CI-`[myrow] <- as.numeric(RVF.model[6]) # lower CI
  senseDat$`CI+`[myrow] <- as.numeric(RVF.model[7]) # lower CI

}

# write df
senseDat.R <- senseDat
senseDat.R$VF <- "RVF"
```

Regardless of the correlation, it appears that the effect is inhibitory. 

## Left visual field

First, we run again for LVF data.

```{r simulateL}
# now get the correlations for the RVF
corrL <- mean(data$r, na.rm= TRUE)
# create RVF data 
LVF_dat <- dplyr::select(data, Full.title, Source.name, Source.year, LVF.High.N, LVF.High.N.sd, LVF.Low.N, LVF.Low.N.sd, Sample.size)
# rename for package
LVF_dat <- LVF_dat %>% 
  rename(
    study    = Full.title,
    highN    = LVF.High.N,
    highN_sd = LVF.High.N.sd,
    lowN     = LVF.Low.N,
    lowN_sd  = LVF.Low.N.sd)
# add columns
LVF_dat$corr <- corrL
LVF_dat$VF <- "LVF"
# ensure formatted correctly
LVF_dat$sample_size <- as.numeric(LVF_dat$Sample.size)
LVF_dat$highN <- as.numeric(as.character(LVF_dat$highN))
LVF_dat$highN_sd <- as.numeric(as.character(LVF_dat$highN_sd))
LVF_dat$lowN <- as.numeric(as.character(LVF_dat$lowN))
LVF_dat$lowN_sd <- as.numeric(as.character(LVF_dat$lowN_sd))
LVF_dat$corr <- as.numeric(as.character(LVF_dat$corr))
LVF_dat$study <- as.character(LVF_dat$study)
```

Now run the analysis for the LVF.

```{r analysesL}
# calculate the ES
#W do this for LVF
LVF.ES <- ES(LVF_dat, LVF_dat$highN, LVF_dat$lowN, LVF_dat$highN_sd, LVF_dat$lowN_sd, LVF_dat$sample_size, LVF_dat$corr)
# now run the meta analysis
LVF.model <- rma(yi= MD, vi= var, sei= se, data=LVF.ES, method="SJ", test="knha" , digits=3, slab= study)
# print
LVF.model
regtest(LVF.model)
# plot
forest(LVF.model)
grid.text("(A)", .5, .85)
# FUNNEL plots
# set up 2x2 array for plotting
par(mfrow=c(2,2))
# draw funnel plots
funnel(LVF.model, main="Standard Error [LVF]", xlab="Effect size (ms)")
funnel(LVF.model, yaxis="vi", main="Sampling Variance [LVF]", xlab="Effect size (ms)")
funnel(LVF.model, yaxis="seinv", main="Inverse Standard Error [LVF]", xlab="Effect size (ms)")
funnel(LVF.model, yaxis="vinv", main="Inverse Sampling Variance [LVF]", xlab="Effect size (ms)")
```

The estimate is significantly different from zero, so we can conlcude that the effect is truely facilitatory in the LVF/right hemisphere hemisphere. Now let's run some sensitivity analyses using predetermined levels of correlation.

```{r sensitivityL}
# specify correlations
corlist <- c(.2, .5, .8)
# create temporary data to write to before placing within forCurve
senseDat <- data.frame(matrix(ncol = 5, nrow = length(corlist)))
  colnames(senseDat) <- c("cor", "beta", "CI-", "CI+", "p")
# set row counter
myrow <- 0
# start sensiticity analysis
for (i in corlist) {
  
  LVF.ES <- ES(LVF_dat, LVF_dat$highN, LVF_dat$lowN, LVF_dat$highN_sd, LVF_dat$lowN_sd, LVF_dat$sample_size, i)
  # now run the meta analysis
  LVF.model <- rma(yi= MD, vi= var, sei= se, data=LVF.ES, method="SJ", test="knha" , digits=3)

  # flip counter
  myrow <- myrow+1
  # take the useful estimates
  senseDat$cor[myrow]   <- as.numeric(i) # cor
  senseDat$beta[myrow]  <- as.numeric(LVF.model[2]) # beta
  senseDat$p[myrow]     <- as.numeric(LVF.model[5]) # p
  senseDat$`CI-`[myrow] <- as.numeric(LVF.model[6]) # lower CI
  senseDat$`CI+`[myrow] <- as.numeric(LVF.model[7]) # lower CI

}

# write df
senseDat.L <- senseDat
senseDat.L$VF <- "LVF"
# merge
# write df
senseDat.full <- rbind(senseDat.L, senseDat.R)
# now plot the outcome
ggplot(senseDat.full, aes(x=as.factor(cor), y=beta, fill=as.factor(cor))) + 
  geom_bar(stat="identity", color="black", position=position_dodge()) +
  geom_errorbar(aes(ymin=`CI-`, ymax=`CI+`), width=.2, position=position_dodge(.9)) +
  facet_wrap(.~ VF) + scale_fill_grey(start = 0.3, end = .9) +
  theme_bw(18) + xlab("Correlation estimate") + ylab("RE model estimate of N effect") + theme(legend.position="top") +
  theme(legend.position = 'none', legend.title=element_blank())  + facet_wrap(.~VF) 
  
```

Regardless of the correlation used, the effect os always facilitatory.

# Exploratory analysis

To explore heterogenetiy, we conducted exploratory analysis using meta-regression.

## Size of the N manipulation

```{r meta-regression2}
data$ndif <- as.numeric(data$High.N) - as.numeric(data$Low.N)
# get number ndif
ndif.dat <- dplyr::select(data, Full.title, ndif)
# RVF
# merge them
RVF.ES<- merge(RVF.ES, ndif.dat, by.x= "study", by.y= "Full.title")
# now run lm
rma(yi= MD, vi= var, mods = ~ ndif, data=RVF.ES)
# LVF
# merge them
LVF.ES<- merge(LVF.ES, ndif.dat, by.x= "study", by.y= "Full.title")
# now run lm
rma(yi= MD, vi= var, mods = ~ ndif, data=LVF.ES)
```

There isn't much support for the strength of the manipulation influencing this. 

